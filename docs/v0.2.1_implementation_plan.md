# EmbedKit v0.2.1 Implementation Plan

**Version**: 0.2.1 (Major Upgrade)
**Created**: November 2024
**Updated**: December 2024
**Status**: Complete (Ready for Release)

## Implementation Progress

### Completed âœ…

#### Metal 4 API Implementation
- [x] `Metal4CommandAllocator` - Command allocator pool
- [x] `Metal4CommandEncoding` - Tensor-aware command encoding
- [x] `Metal4ResourceManagement` - Residency set management
- [x] `Metal4Extensions` - Device capability detection
- [x] `TensorDescriptorFactory` - MTLTensorDescriptor creation
- [x] `TensorResultExtractor` - Type-safe result extraction
- [x] `TensorLifecycleManager` - Memory lifecycle management
- [x] `TensorOperationDispatcher` - Batch operation dispatch
- [x] `TensorStorageManager` - Buffer allocation/pooling
- [x] New Metal shaders (V2 variants)

#### Configuration Factories (Batch 4)
- [x] `EmbeddingConfiguration.forSemanticSearch()`
- [x] `EmbeddingConfiguration.forRAG()`
- [x] `EmbeddingConfiguration.forClustering()`
- [x] `EmbeddingConfiguration.forSimilarity()`
- [x] `EmbeddingConfiguration.forDocuments()`
- [x] `EmbeddingConfiguration.forShortText()`
- [x] `EmbeddingConfiguration.forMiniLM()`
- [x] `EmbeddingConfiguration.forBERT()`

#### VectorCore Foundation (Batch 1)
- [x] `VectorProducer` protocol - Cross-package embedding interface
- [x] `OperationProgress` struct - Shared progress reporting
- [x] `VSKError` protocol - Unified error handling
- [x] `VectorProducerHints` - Producer characteristics hints

#### BatchProgress + Progress Reporting (Batch 2)
- [x] `BatchProgress` struct with `OperationProgress` integration
- [x] Throughput metrics (items/sec, tokens processed)
- [x] Factory methods (started, completed, batchCompleted)
- [x] Progress callbacks in `AdaptiveBatcher`

#### Error System Overhaul (Batch 3)
- [x] `EmbedKitError: VSKError` conformance
- [x] Error codes in 2000-2999 range
- [x] `isRecoverable`, `domain`, `context` properties
- [x] Recovery suggestions for all error cases

#### EmbeddingGenerator Core (Batch 5)
- [x] `EmbeddingGenerator` actor implementation
- [x] `VectorProducer` protocol conformance
- [x] Batch embedding with `produce(_:)` methods
- [x] `GeneratorConfiguration` with factory presets

#### EmbeddingGenerator Advanced (Batch 6)
- [x] Streaming via `generateWithProgress(_:)`
- [x] Cancellation support via `Task.checkCancellation()`
- [x] ID-preserving batches (`produceWithIDs`, `generateBatchWithIDs`)
- [x] `warmup()` and `release()` lifecycle methods

#### MetalContext Preparation (Batch 9)
- [x] `SharedMetalConfiguration` - Cross-package config
- [x] `SharedBufferFactory` - Buffer reuse across packages

#### MetalContext Integration (Batch 10)
- [x] `SharedMetalContextManager` actor - Unified GPU resource management
- [x] VectorAccelerate MetalContext integration
- [x] EmbedKit MetalAccelerator integration
- [x] Cross-package buffer sharing
- [x] `SharedContextStatistics` for monitoring

#### Cross-Package Integration Testing (Batch 11)
- [x] `MetalContextIntegrationTests`
- [x] `SharedMetalContextManagerTests`
- [x] `CrossPackageIntegrationTests`
- [x] `V020IntegrationTests`

#### Comprehensive Test Coverage
- [x] Phase 1 Metal 4 Tests (~100 tests)
  - `CommandAllocatorTests`
  - `TensorDescriptorFactoryTests`
  - `TensorResultExtractorTests`
  - `MetalDeviceExtensionsTests`
  - `TensorLifecycleManagerTests`
  - `TensorOperationDispatcherTests`
  - `TensorStorageManagerTests`
  - `Metal4CommandEncodingTests`
  - `Metal4ResourceManagementTests`
  - `Metal4EdgeCaseTests`
- [x] Phase 2 Streaming Tests (~100 tests)
  - `RateLimiterComprehensiveTests` (45+ tests)
  - `BackPressureComprehensiveTests` (50+ tests)
- [x] Phase 3 Embedding Tests (~50 tests)
  - `RerankingStrategyComprehensiveTests` (48 tests)
- [x] CI Configuration Updated
  - Tests batched across `test-metal`, `test-streaming`, `test-embedding` jobs
  - Max ~300 tests per job

#### Test Statistics
- **Total Tests**: 1431 (up from 578)
- **Total Suites**: 358 (up from 159)
- **Test Coverage Increase**: ~147%

### Pending ðŸ“‹

- [ ] Batch 12: Final Polish + Release
  - [ ] Version bump to 0.2.1
  - [ ] CHANGELOG finalization
  - [ ] Tag release

---

## Overview

EmbedKit v0.2.1 is a major upgrade combining:
- **GournalCore Integration Requests**: EmbeddingGenerator, BatchProgress, Configuration Factories, Error Enhancements
- **VSK Tight Integration**: VectorProducer protocol, VSKError system, shared MetalContext

This document is structured for **multi-agent parallel execution**.

---

## Dependency Graph

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           WEEK 1 (Parallel Execution)          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                â”‚                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    BATCH 1      â”‚  â”‚ BATCH 4 â”‚   â”‚    BATCH 9    â”‚
                    â”‚  VectorCore     â”‚  â”‚ Config  â”‚   â”‚ MetalContext  â”‚
                    â”‚  Foundation     â”‚  â”‚Factoriesâ”‚   â”‚  Preparation  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚                â”‚                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                    WEEK 2                        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚                â”‚                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    BATCH 2      â”‚ â”‚  BATCH 5 â”‚  â”‚    BATCH 10    â”‚
                    â”‚  BatchProgress  â”‚ â”‚EmbedGen  â”‚  â”‚ MetalContext   â”‚
                    â”‚   + Progress    â”‚ â”‚  Core    â”‚  â”‚  Integration   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚               â”‚                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                    WEEK 3                        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚               â”‚                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    BATCH 3      â”‚ â”‚  BATCH 6 â”‚  â”‚    BATCH 11    â”‚
                    â”‚  Error System   â”‚ â”‚ EmbedGen â”‚  â”‚   Integration  â”‚
                    â”‚  Overhaul       â”‚ â”‚ Advanced â”‚  â”‚    Testing     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚               â”‚                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                    WEEK 4                        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚              BATCHES 7, 8, 12                    â”‚
                    â”‚    Testing + Documentation + Release            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## WEEK 1: Parallel Execution (Batches 1, 4, 9)

These three batches have **NO dependencies on each other** and can be worked on simultaneously by different agents.

---

# BATCH 1: VectorCore Foundation

**Agent Assignment**: Agent A
**Estimated Effort**: 6-8 hours
**Package**: VectorCore (dependency of EmbedKit)
**Risk Level**: Medium (modifies shared dependency)

## Objective

Add foundational types to VectorCore that will be consumed by EmbedKit:
1. `VectorProducer` protocol
2. `OperationProgress` struct
3. `VSKError` protocol

## File Changes

### New Files to Create

#### 1. `VectorCore/Sources/VectorCore/Protocols/VectorProducer.swift`

```swift
// VectorCore - VectorProducer Protocol
// Defines the interface for embedding producers

import Foundation

/// Protocol for types that produce vector embeddings from text
/// Enables cross-package interoperability between EmbedKit and VectorIndex
public protocol VectorProducer: Sendable {
    /// The dimensionality of produced embeddings
    var dimensions: Int { get }

    /// Whether the producer normalizes output vectors
    var producesNormalizedVectors: Bool { get }

    /// Produce embeddings for a batch of texts
    /// - Parameter texts: Input texts to embed
    /// - Returns: Array of embeddings matching input order
    /// - Throws: VSKError on failure
    func produce(_ texts: [String]) async throws -> [[Float]]

    /// Produce embedding for a single text
    /// - Parameter text: Input text to embed
    /// - Returns: Embedding vector
    /// - Throws: VSKError on failure
    func produce(_ text: String) async throws -> [Float]
}

// MARK: - Default Implementations

public extension VectorProducer {
    /// Default single-text implementation delegates to batch
    func produce(_ text: String) async throws -> [Float] {
        let results = try await produce([text])
        guard let first = results.first else {
            throw VectorError.invalidOperation(
                "Producer returned empty results",
                context: ErrorContext()
            )
        }
        return first
    }
}

/// Hints for vector consumers about producer characteristics
public struct VectorProducerHints: Sendable, Equatable {
    /// Expected embedding dimensions
    public let dimensions: Int

    /// Whether vectors are L2-normalized
    public let isNormalized: Bool

    /// Recommended batch size for optimal throughput
    public let optimalBatchSize: Int

    /// Maximum supported batch size
    public let maxBatchSize: Int

    public init(
        dimensions: Int,
        isNormalized: Bool = true,
        optimalBatchSize: Int = 32,
        maxBatchSize: Int = 128
    ) {
        self.dimensions = dimensions
        self.isNormalized = isNormalized
        self.optimalBatchSize = optimalBatchSize
        self.maxBatchSize = maxBatchSize
    }
}
```

#### 2. `VectorCore/Sources/VectorCore/Progress/OperationProgress.swift`

```swift
// VectorCore - OperationProgress
// Shared progress reporting type across VSK packages

import Foundation

/// Represents progress of a long-running operation
public struct OperationProgress: Sendable, Equatable {
    /// Current item index (0-based)
    public let current: Int

    /// Total number of items
    public let total: Int

    /// Operation phase/stage name
    public let phase: String

    /// Optional message with details
    public let message: String?

    /// Timestamp when progress was recorded
    public let timestamp: Date

    /// Progress as fraction [0.0, 1.0]
    public var fraction: Double {
        guard total > 0 else { return 0.0 }
        return Double(current) / Double(total)
    }

    /// Progress as percentage [0, 100]
    public var percentage: Int {
        Int(fraction * 100)
    }

    /// Whether operation is complete
    public var isComplete: Bool {
        current >= total
    }

    /// Estimated time remaining (if calculable)
    public let estimatedTimeRemaining: TimeInterval?

    public init(
        current: Int,
        total: Int,
        phase: String = "Processing",
        message: String? = nil,
        estimatedTimeRemaining: TimeInterval? = nil,
        timestamp: Date = Date()
    ) {
        self.current = max(0, current)
        self.total = max(0, total)
        self.phase = phase
        self.message = message
        self.estimatedTimeRemaining = estimatedTimeRemaining
        self.timestamp = timestamp
    }

    // MARK: - Factory Methods

    /// Create progress for start of operation
    public static func started(total: Int, phase: String = "Starting") -> OperationProgress {
        OperationProgress(current: 0, total: total, phase: phase)
    }

    /// Create progress for completion
    public static func completed(total: Int, phase: String = "Complete") -> OperationProgress {
        OperationProgress(current: total, total: total, phase: phase)
    }

    /// Create indeterminate progress (total unknown)
    public static func indeterminate(current: Int, phase: String) -> OperationProgress {
        OperationProgress(current: current, total: 0, phase: phase)
    }
}

// MARK: - Progress Stream Support

/// AsyncSequence wrapper for progress updates
public struct ProgressStream<Element: Sendable>: AsyncSequence, Sendable {
    public typealias AsyncIterator = Iterator

    private let stream: AsyncThrowingStream<(Element, OperationProgress), Error>

    public init(_ stream: AsyncThrowingStream<(Element, OperationProgress), Error>) {
        self.stream = stream
    }

    public func makeAsyncIterator() -> Iterator {
        Iterator(iterator: stream.makeAsyncIterator())
    }

    public struct Iterator: AsyncIteratorProtocol {
        var iterator: AsyncThrowingStream<(Element, OperationProgress), Error>.AsyncIterator

        public mutating func next() async throws -> (Element, OperationProgress)? {
            try await iterator.next()
        }
    }
}
```

#### 3. `VectorCore/Sources/VectorCore/Errors/VSKError.swift`

```swift
// VectorCore - VSKError Protocol
// Unified error protocol for all VSK packages

import Foundation

/// Protocol for errors across VSK package family
/// Provides consistent error handling and debugging information
public protocol VSKError: Error, Sendable, CustomStringConvertible {
    /// Unique error code within domain
    var errorCode: Int { get }

    /// Error domain (e.g., "EmbedKit", "VectorIndex", "VectorAccelerate")
    var domain: String { get }

    /// Whether this error is potentially recoverable
    var isRecoverable: Bool { get }

    /// Suggested recovery action, if any
    var recoverySuggestion: String? { get }

    /// Underlying error that caused this error
    var underlyingError: (any Error)? { get }

    /// Context information for debugging
    var context: ErrorContext { get }
}

// MARK: - Default Implementations

public extension VSKError {
    var description: String {
        var desc = "[\(domain):\(errorCode)] \(localizedDescription)"
        if let suggestion = recoverySuggestion {
            desc += " Suggestion: \(suggestion)"
        }
        return desc
    }

    var recoverySuggestion: String? { nil }
    var underlyingError: (any Error)? { nil }
}

// MARK: - Error Codes

/// Standard error code ranges for VSK packages
public enum VSKErrorCodeRange {
    /// VectorCore: 1000-1999
    public static let vectorCore = 1000..<2000

    /// EmbedKit: 2000-2999
    public static let embedKit = 2000..<3000

    /// VectorIndex: 3000-3999
    public static let vectorIndex = 3000..<4000

    /// VectorAccelerate: 4000-4999
    public static let vectorAccelerate = 4000..<5000
}
```

### Files to Modify

#### Update `VectorCore/Sources/VectorCore/Errors/VectorError.swift`

Add conformance to `VSKError`:

```swift
// Add to existing VectorError enum:

extension VectorError: VSKError {
    public var errorCode: Int {
        switch self {
        case .invalidDimensions: return 1001
        case .invalidOperation: return 1002
        case .outOfBounds: return 1003
        case .allocationFailed: return 1004
        case .alignmentError: return 1005
        // ... map all cases
        }
    }

    public var domain: String { "VectorCore" }

    public var isRecoverable: Bool {
        switch self {
        case .invalidDimensions, .invalidOperation: return false
        case .allocationFailed: return true // Can retry with smaller allocation
        // ... evaluate each case
        }
    }
}
```

## Tests to Create

### `VectorCore/Tests/VectorCoreTests/VectorProducerTests.swift`

```swift
import Testing
@testable import VectorCore

@Suite("VectorProducer Protocol")
struct VectorProducerTests {

    struct MockProducer: VectorProducer {
        let dimensions: Int = 4
        let producesNormalizedVectors: Bool = true

        func produce(_ texts: [String]) async throws -> [[Float]] {
            texts.map { _ in [0.5, 0.5, 0.5, 0.5] }
        }
    }

    @Test("Default single produce delegates to batch")
    func singleProduceDelegatesToBatch() async throws {
        let producer = MockProducer()
        let result = try await producer.produce("test")
        #expect(result.count == 4)
    }

    @Test("VectorProducerHints stores values correctly")
    func hintsStoreValues() {
        let hints = VectorProducerHints(
            dimensions: 384,
            isNormalized: true,
            optimalBatchSize: 32,
            maxBatchSize: 128
        )

        #expect(hints.dimensions == 384)
        #expect(hints.isNormalized == true)
        #expect(hints.optimalBatchSize == 32)
        #expect(hints.maxBatchSize == 128)
    }
}
```

### `VectorCore/Tests/VectorCoreTests/OperationProgressTests.swift`

```swift
import Testing
@testable import VectorCore

@Suite("OperationProgress")
struct OperationProgressTests {

    @Test("Fraction calculation is correct")
    func fractionCalculation() {
        let progress = OperationProgress(current: 50, total: 100, phase: "Test")
        #expect(progress.fraction == 0.5)
        #expect(progress.percentage == 50)
    }

    @Test("Zero total returns zero fraction")
    func zeroTotalFraction() {
        let progress = OperationProgress(current: 10, total: 0, phase: "Test")
        #expect(progress.fraction == 0.0)
    }

    @Test("IsComplete when current >= total")
    func isCompleteCheck() {
        let incomplete = OperationProgress(current: 5, total: 10, phase: "Test")
        let complete = OperationProgress(current: 10, total: 10, phase: "Test")

        #expect(incomplete.isComplete == false)
        #expect(complete.isComplete == true)
    }

    @Test("Factory methods work correctly")
    func factoryMethods() {
        let started = OperationProgress.started(total: 100)
        #expect(started.current == 0)
        #expect(started.total == 100)

        let completed = OperationProgress.completed(total: 100)
        #expect(completed.isComplete == true)

        let indeterminate = OperationProgress.indeterminate(current: 5, phase: "Loading")
        #expect(indeterminate.total == 0)
    }
}
```

## Acceptance Criteria

- [ ] `VectorProducer` protocol compiles and can be conformed to
- [ ] `OperationProgress` supports all progress scenarios
- [ ] `VSKError` protocol defined with error code ranges
- [ ] `VectorError` conforms to `VSKError`
- [ ] All new tests pass
- [ ] VectorCore builds without warnings
- [ ] Documentation comments complete

## Integration Notes

This batch creates types that will be consumed by:
- **Batch 2**: Uses `OperationProgress` for `BatchProgress`
- **Batch 3**: Uses `VSKError` for `EmbedKitError` enhancements
- **Batch 5**: Uses `VectorProducer` for `EmbeddingGenerator`

**No coordination required with Batches 4 or 9.**

---

# BATCH 4: EmbedKit Configuration Factories

**Agent Assignment**: Agent B
**Estimated Effort**: 4-6 hours
**Package**: EmbedKit
**Risk Level**: Low (additive only)

## Objective

Add factory methods to `EmbeddingConfiguration` for common use cases. This is purely additive and doesn't modify existing code.

## File Changes

### File to Modify: `Sources/EmbedKit/Core/Types.swift`

Add extension with factory methods to existing `EmbeddingConfiguration`:

```swift
// MARK: - Configuration Factories

extension EmbeddingConfiguration {

    // MARK: - Use Case Factories

    /// Configuration optimized for semantic search applications
    /// - Parameters:
    ///   - maxLength: Maximum token length (default: 512)
    ///   - normalize: Whether to L2-normalize embeddings (default: true)
    /// - Returns: Configured EmbeddingConfiguration
    public static func forSemanticSearch(
        maxLength: Int = 512,
        normalize: Bool = true
    ) -> EmbeddingConfiguration {
        EmbeddingConfiguration(
            maxTokens: maxLength,
            paddingStrategy: .padToLength(maxLength),
            truncationStrategy: .truncateEnd,
            includeSpecialTokens: true,
            normalizationMode: normalize ? .l2 : .none
        )
    }

    /// Configuration optimized for RAG (Retrieval-Augmented Generation)
    /// - Parameters:
    ///   - chunkSize: Expected chunk size in tokens (default: 256)
    ///   - overlap: Token overlap between chunks handled externally
    /// - Returns: Configured EmbeddingConfiguration
    public static func forRAG(
        chunkSize: Int = 256
    ) -> EmbeddingConfiguration {
        EmbeddingConfiguration(
            maxTokens: chunkSize,
            paddingStrategy: .padToLength(chunkSize),
            truncationStrategy: .truncateEnd,
            includeSpecialTokens: true,
            normalizationMode: .l2
        )
    }

    /// Configuration optimized for clustering/classification
    /// - Parameters:
    ///   - maxLength: Maximum token length (default: 128)
    /// - Returns: Configured EmbeddingConfiguration
    public static func forClustering(
        maxLength: Int = 128
    ) -> EmbeddingConfiguration {
        EmbeddingConfiguration(
            maxTokens: maxLength,
            paddingStrategy: .padToLongest,
            truncationStrategy: .truncateEnd,
            includeSpecialTokens: true,
            normalizationMode: .l2
        )
    }

    /// Configuration for similarity comparison between text pairs
    /// - Parameters:
    ///   - maxLength: Maximum token length for each text (default: 256)
    /// - Returns: Configured EmbeddingConfiguration
    public static func forSimilarity(
        maxLength: Int = 256
    ) -> EmbeddingConfiguration {
        EmbeddingConfiguration(
            maxTokens: maxLength,
            paddingStrategy: .padToLongest,
            truncationStrategy: .truncateEnd,
            includeSpecialTokens: true,
            normalizationMode: .l2
        )
    }

    /// Configuration for document-level embeddings
    /// - Parameters:
    ///   - maxLength: Maximum document length in tokens (default: 2048)
    /// - Returns: Configured EmbeddingConfiguration
    public static func forDocuments(
        maxLength: Int = 2048
    ) -> EmbeddingConfiguration {
        EmbeddingConfiguration(
            maxTokens: maxLength,
            paddingStrategy: .none,
            truncationStrategy: .truncateEnd,
            includeSpecialTokens: true,
            normalizationMode: .l2
        )
    }

    /// Configuration for short text like queries or titles
    /// - Parameters:
    ///   - maxLength: Maximum length (default: 64)
    /// - Returns: Configured EmbeddingConfiguration
    public static func forShortText(
        maxLength: Int = 64
    ) -> EmbeddingConfiguration {
        EmbeddingConfiguration(
            maxTokens: maxLength,
            paddingStrategy: .padToLength(maxLength),
            truncationStrategy: .truncateEnd,
            includeSpecialTokens: true,
            normalizationMode: .l2
        )
    }

    // MARK: - Model-Specific Factories

    /// Configuration for MiniLM models (384 dimensions)
    /// - Parameter useCase: The intended use case
    /// - Returns: Configured EmbeddingConfiguration
    public static func forMiniLM(
        useCase: UseCase = .semanticSearch
    ) -> EmbeddingConfiguration {
        switch useCase {
        case .semanticSearch:
            return .forSemanticSearch(maxLength: 256)
        case .rag:
            return .forRAG(chunkSize: 256)
        case .clustering:
            return .forClustering(maxLength: 128)
        case .similarity:
            return .forSimilarity(maxLength: 256)
        }
    }

    /// Configuration for BERT-base models (768 dimensions)
    /// - Parameter useCase: The intended use case
    /// - Returns: Configured EmbeddingConfiguration
    public static func forBERT(
        useCase: UseCase = .semanticSearch
    ) -> EmbeddingConfiguration {
        switch useCase {
        case .semanticSearch:
            return .forSemanticSearch(maxLength: 512)
        case .rag:
            return .forRAG(chunkSize: 384)
        case .clustering:
            return .forClustering(maxLength: 256)
        case .similarity:
            return .forSimilarity(maxLength: 512)
        }
    }

    /// Common use cases for factory selection
    public enum UseCase: String, Sendable, CaseIterable {
        case semanticSearch
        case rag
        case clustering
        case similarity
    }
}
```

## Tests to Create

### `Tests/EmbedKitTests/ConfigurationFactoryTests.swift`

```swift
import Testing
@testable import EmbedKit

@Suite("Configuration Factories")
struct ConfigurationFactoryTests {

    // MARK: - Use Case Factories

    @Test("forSemanticSearch creates valid config")
    func semanticSearchConfig() {
        let config = EmbeddingConfiguration.forSemanticSearch()

        #expect(config.maxTokens == 512)
        #expect(config.normalizationMode == .l2)
        #expect(config.includeSpecialTokens == true)
    }

    @Test("forSemanticSearch with custom params")
    func semanticSearchCustom() {
        let config = EmbeddingConfiguration.forSemanticSearch(
            maxLength: 256,
            normalize: false
        )

        #expect(config.maxTokens == 256)
        #expect(config.normalizationMode == .none)
    }

    @Test("forRAG creates valid config")
    func ragConfig() {
        let config = EmbeddingConfiguration.forRAG(chunkSize: 512)

        #expect(config.maxTokens == 512)
        #expect(config.normalizationMode == .l2)
    }

    @Test("forClustering creates valid config")
    func clusteringConfig() {
        let config = EmbeddingConfiguration.forClustering()

        #expect(config.maxTokens == 128)
        #expect(config.paddingStrategy == .padToLongest)
    }

    @Test("forSimilarity creates valid config")
    func similarityConfig() {
        let config = EmbeddingConfiguration.forSimilarity()

        #expect(config.maxTokens == 256)
        #expect(config.normalizationMode == .l2)
    }

    @Test("forDocuments creates valid config")
    func documentsConfig() {
        let config = EmbeddingConfiguration.forDocuments()

        #expect(config.maxTokens == 2048)
        #expect(config.paddingStrategy == .none)
    }

    @Test("forShortText creates valid config")
    func shortTextConfig() {
        let config = EmbeddingConfiguration.forShortText()

        #expect(config.maxTokens == 64)
    }

    // MARK: - Model-Specific Factories

    @Test("forMiniLM with different use cases")
    func miniLMConfigs() {
        let search = EmbeddingConfiguration.forMiniLM(useCase: .semanticSearch)
        let rag = EmbeddingConfiguration.forMiniLM(useCase: .rag)
        let cluster = EmbeddingConfiguration.forMiniLM(useCase: .clustering)

        #expect(search.maxTokens == 256)
        #expect(rag.maxTokens == 256)
        #expect(cluster.maxTokens == 128)
    }

    @Test("forBERT with different use cases")
    func bertConfigs() {
        let search = EmbeddingConfiguration.forBERT(useCase: .semanticSearch)
        let rag = EmbeddingConfiguration.forBERT(useCase: .rag)

        #expect(search.maxTokens == 512)
        #expect(rag.maxTokens == 384)
    }

    // MARK: - UseCase Enum

    @Test("UseCase is CaseIterable")
    func useCaseIterable() {
        let cases = EmbeddingConfiguration.UseCase.allCases
        #expect(cases.count == 4)
        #expect(cases.contains(.semanticSearch))
        #expect(cases.contains(.rag))
        #expect(cases.contains(.clustering))
        #expect(cases.contains(.similarity))
    }
}
```

## Acceptance Criteria

- [ ] All factory methods compile and return valid configurations
- [ ] Factory methods have comprehensive documentation
- [ ] All tests pass
- [ ] No changes to existing `EmbeddingConfiguration` initializers
- [ ] EmbedKit builds without warnings

## Integration Notes

This batch is completely independent and can be merged at any time.

**No coordination required with Batches 1 or 9.**

---

# BATCH 9: VectorAccelerate MetalContext Preparation

**Agent Assignment**: Agent C
**Estimated Effort**: 4-6 hours
**Package**: VectorAccelerate (dependency of EmbedKit)
**Risk Level**: Low (additive, preparation work)

## Objective

Prepare VectorAccelerate's `MetalContext` for sharing with EmbedKit. This involves:
1. Adding configuration options for multi-package sharing
2. Adding buffer factory exposure
3. Creating sharing protocol

## File Changes

### New File: `VectorAccelerate/Sources/VectorAccelerate/Core/SharedMetalContext.swift`

```swift
// VectorAccelerate - SharedMetalContext
// Protocol and types for cross-package Metal resource sharing

import Foundation
#if canImport(Metal)
import Metal
#endif

/// Protocol for types that can share a MetalContext
public protocol MetalContextShareable: Sendable {
    /// The shared Metal context
    var metalContext: MetalContext { get async }

    /// Whether this instance owns the context (vs borrowed)
    var ownsContext: Bool { get }
}

/// Configuration for shared MetalContext usage
public struct SharedMetalConfiguration: Sendable, Equatable {
    /// Maximum buffer pool size in megabytes
    public let maxBufferPoolMB: Int

    /// Whether to enable buffer reuse across packages
    public let enableCrossPackageBufferReuse: Bool

    /// Priority for Metal command queue
    public let commandQueuePriority: CommandQueuePriority

    /// Whether to collect performance metrics
    public let enableMetrics: Bool

    public init(
        maxBufferPoolMB: Int = 256,
        enableCrossPackageBufferReuse: Bool = true,
        commandQueuePriority: CommandQueuePriority = .default,
        enableMetrics: Bool = false
    ) {
        self.maxBufferPoolMB = maxBufferPoolMB
        self.enableCrossPackageBufferReuse = enableCrossPackageBufferReuse
        self.commandQueuePriority = commandQueuePriority
        self.enableMetrics = enableMetrics
    }

    /// Configuration optimized for EmbedKit integration
    public static let forEmbedKit = SharedMetalConfiguration(
        maxBufferPoolMB: 128,
        enableCrossPackageBufferReuse: true,
        commandQueuePriority: .default,
        enableMetrics: false
    )

    /// Configuration optimized for VectorIndex integration
    public static let forVectorIndex = SharedMetalConfiguration(
        maxBufferPoolMB: 512,
        enableCrossPackageBufferReuse: true,
        commandQueuePriority: .high,
        enableMetrics: false
    )

    public enum CommandQueuePriority: String, Sendable, CaseIterable {
        case low
        case `default`
        case high
    }
}

#if canImport(Metal)
/// Shareable buffer factory for cross-package buffer allocation
public actor SharedBufferFactory {
    private let device: MTLDevice
    private var bufferPool: [Int: [MTLBuffer]] = [:]  // Size -> Available buffers
    private let maxPoolSize: Int
    private var currentPoolSize: Int = 0

    public init(device: MTLDevice, maxPoolSizeMB: Int = 128) {
        self.device = device
        self.maxPoolSize = maxPoolSizeMB * 1024 * 1024
    }

    /// Get or create a buffer of at least the specified size
    public func getBuffer(minimumSize: Int, options: MTLResourceOptions = .storageModeShared) -> MTLBuffer? {
        // Round up to power of 2 for better reuse
        let alignedSize = nextPowerOfTwo(minimumSize)

        // Check pool first
        if var available = bufferPool[alignedSize], !available.isEmpty {
            let buffer = available.removeLast()
            bufferPool[alignedSize] = available
            return buffer
        }

        // Create new buffer
        return device.makeBuffer(length: alignedSize, options: options)
    }

    /// Return a buffer to the pool for reuse
    public func returnBuffer(_ buffer: MTLBuffer) {
        let size = buffer.length

        // Don't pool if we're at capacity
        guard currentPoolSize + size <= maxPoolSize else { return }

        if bufferPool[size] == nil {
            bufferPool[size] = []
        }
        bufferPool[size]?.append(buffer)
        currentPoolSize += size
    }

    /// Clear all pooled buffers
    public func clearPool() {
        bufferPool.removeAll()
        currentPoolSize = 0
    }

    /// Current pool utilization
    public var poolUtilization: Double {
        Double(currentPoolSize) / Double(maxPoolSize)
    }

    private func nextPowerOfTwo(_ n: Int) -> Int {
        var v = n - 1
        v |= v >> 1
        v |= v >> 2
        v |= v >> 4
        v |= v >> 8
        v |= v >> 16
        return v + 1
    }
}
#endif
```

### File to Modify: `VectorAccelerate/Sources/VectorAccelerate/Core/MetalContext.swift`

Add sharing support to existing `MetalContext`:

```swift
// Add to MetalContext actor:

extension MetalContext {
    /// Create a MetalContext configured for sharing with EmbedKit
    public static func forEmbedKitSharing(
        device: MTLDevice? = nil
    ) async throws -> MetalContext {
        let config = SharedMetalConfiguration.forEmbedKit
        return try await MetalContext(
            device: device,
            maxBufferPoolMB: config.maxBufferPoolMB
        )
    }

    /// Get the shared buffer factory for cross-package buffer allocation
    public var sharedBufferFactory: SharedBufferFactory {
        get async {
            // Return or create buffer factory
            // Implementation depends on existing MetalContext structure
        }
    }

    /// Statistics about shared resource usage
    public struct SharingStatistics: Sendable {
        public let buffersShared: Int
        public let bytesShared: Int64
        public let poolUtilization: Double
    }

    /// Get current sharing statistics
    public func getSharingStatistics() async -> SharingStatistics {
        let factory = await sharedBufferFactory
        return SharingStatistics(
            buffersShared: 0,  // Track in implementation
            bytesShared: 0,
            poolUtilization: await factory.poolUtilization
        )
    }
}
```

## Tests to Create

### `VectorAccelerate/Tests/VectorAccelerateTests/SharedMetalContextTests.swift`

```swift
import Testing
@testable import VectorAccelerate

#if canImport(Metal)
import Metal
#endif

@Suite("Shared MetalContext")
struct SharedMetalContextTests {

    @Test("SharedMetalConfiguration default values")
    func configDefaults() {
        let config = SharedMetalConfiguration()

        #expect(config.maxBufferPoolMB == 256)
        #expect(config.enableCrossPackageBufferReuse == true)
        #expect(config.commandQueuePriority == .default)
    }

    @Test("SharedMetalConfiguration factory presets")
    func configPresets() {
        let embedKit = SharedMetalConfiguration.forEmbedKit
        let vectorIndex = SharedMetalConfiguration.forVectorIndex

        #expect(embedKit.maxBufferPoolMB == 128)
        #expect(vectorIndex.maxBufferPoolMB == 512)
    }

    #if canImport(Metal)
    @Test("SharedBufferFactory allocates buffers")
    func factoryAllocates() async throws {
        guard let device = MTLCreateSystemDefaultDevice() else {
            throw TestSkipped("Metal not available")
        }

        let factory = SharedBufferFactory(device: device, maxPoolSizeMB: 10)

        let buffer = await factory.getBuffer(minimumSize: 1024)
        #expect(buffer != nil)
        #expect(buffer!.length >= 1024)
    }

    @Test("SharedBufferFactory reuses returned buffers")
    func factoryReuses() async throws {
        guard let device = MTLCreateSystemDefaultDevice() else {
            throw TestSkipped("Metal not available")
        }

        let factory = SharedBufferFactory(device: device, maxPoolSizeMB: 10)

        // Get and return a buffer
        let buffer1 = await factory.getBuffer(minimumSize: 1024)!
        await factory.returnBuffer(buffer1)

        // Get another buffer of same size - should be the same one
        let buffer2 = await factory.getBuffer(minimumSize: 1024)
        #expect(buffer2 != nil)
    }

    @Test("SharedBufferFactory respects pool limit")
    func factoryRespectsLimit() async throws {
        guard let device = MTLCreateSystemDefaultDevice() else {
            throw TestSkipped("Metal not available")
        }

        let factory = SharedBufferFactory(device: device, maxPoolSizeMB: 1)  // 1MB limit

        // Return large buffer - should not be pooled
        let largeBuffer = device.makeBuffer(length: 2 * 1024 * 1024)!  // 2MB
        await factory.returnBuffer(largeBuffer)

        // Pool should still be empty
        let utilization = await factory.poolUtilization
        #expect(utilization == 0.0)
    }

    @Test("SharedBufferFactory clearPool works")
    func factoryClearsPool() async throws {
        guard let device = MTLCreateSystemDefaultDevice() else {
            throw TestSkipped("Metal not available")
        }

        let factory = SharedBufferFactory(device: device, maxPoolSizeMB: 10)

        let buffer = await factory.getBuffer(minimumSize: 1024)!
        await factory.returnBuffer(buffer)
        await factory.clearPool()

        let utilization = await factory.poolUtilization
        #expect(utilization == 0.0)
    }
    #endif
}

struct TestSkipped: Error {
    let reason: String
    init(_ reason: String) { self.reason = reason }
}
```

## Acceptance Criteria

- [ ] `SharedMetalConfiguration` provides all configuration options
- [ ] `SharedBufferFactory` enables buffer reuse
- [ ] `MetalContext` extension methods compile
- [ ] All tests pass (with Metal device available)
- [ ] VectorAccelerate builds without warnings

## Integration Notes

This batch prepares infrastructure for **Batch 10** (MetalContext Integration).

**No coordination required with Batches 1 or 4.**

---

## WEEK 2-4: Remaining Batches

### Batch 2: EmbedKit BatchProgress + Progress Reporting (depends on Batch 1)

**Estimated Effort**: 6-8 hours

- Create `BatchProgress` struct using `OperationProgress` from VectorCore
- Add progress callbacks to `AdaptiveBatcher`
- Add `AsyncStream`-based progress reporting
- Tests for progress accuracy

### Batch 3: EmbedKit Error System Overhaul (depends on Batch 1)

**Estimated Effort**: 6-8 hours

- Make `EmbedKitError` conform to `VSKError`
- Add `errorCode`, `isRecoverable`, `domain` properties
- Add error code documentation
- Maintain backward compatibility

### Batch 5: EmbeddingGenerator Core Implementation (depends on Batches 1, 4)

**Estimated Effort**: 8-10 hours

- Create `EmbeddingGenerator` actor
- Implement headless embedding generation
- Add batch processing with progress
- Integration with existing models

### Batch 6: EmbeddingGenerator Advanced Features (depends on Batch 5)

**Estimated Effort**: 6-8 hours

- Add streaming support
- Add cancellation support
- Performance optimization
- Memory management

### Batch 7: Testing Phase 1 (depends on Batches 2, 3, 5)

**Estimated Effort**: 8-10 hours

- Comprehensive unit tests
- Integration tests
- Performance benchmarks
- Edge case testing

### Batch 8: Documentation + Migration Guide (depends on Batch 7)

**Estimated Effort**: 4-6 hours

- API documentation
- Migration guide from v0.1.0
- Usage examples
- Best practices

### Batch 10: MetalContext Integration (depends on Batches 9, 5)

**Estimated Effort**: 8-10 hours

- Connect EmbedKit to VectorAccelerate's MetalContext
- Implement buffer sharing
- Add Metal resource pooling

### Batch 11: Integration Testing (depends on Batch 10)

**Estimated Effort**: 6-8 hours

- Cross-package integration tests
- Memory pressure testing
- Concurrent access testing

### Batch 12: Final Polish + Release (depends on all)

**Estimated Effort**: 4-6 hours

- Version bump
- CHANGELOG update
- Final testing
- Tag release

---

## Multi-Agent Coordination Protocol

### Communication Points

Since Batches 1, 4, and 9 work on different packages with no shared files, agents can work completely independently. However, establish these checkpoints:

1. **Start Sync**: All agents confirm they've read this document
2. **Midpoint Check**: Brief status update after ~3 hours
3. **Completion Signal**: Agent signals when batch is complete

### Merge Order

Even though work is parallel, merges should happen in this order to avoid conflicts:

1. **Batch 1** (VectorCore) - Merge first as it's a dependency
2. **Batch 9** (VectorAccelerate) - Merge second
3. **Batch 4** (EmbedKit) - Merge last

### File Ownership

| Batch | Package | Owned Directories |
|-------|---------|-------------------|
| 1 | VectorCore | `Sources/VectorCore/Protocols/`, `Sources/VectorCore/Progress/`, `Sources/VectorCore/Errors/` |
| 4 | EmbedKit | `Sources/EmbedKit/Core/Types.swift` (extension only) |
| 9 | VectorAccelerate | `Sources/VectorAccelerate/Core/` |

### Testing Before Merge

Each agent must ensure:
1. Their package builds independently
2. All new tests pass
3. Existing tests still pass
4. No compiler warnings

---

## Success Metrics

### Batch 1
- VectorCore compiles
- 6+ new tests pass
- No breaking changes to existing API

### Batch 4
- EmbedKit compiles
- 10+ new tests pass
- All existing tests still pass

### Batch 9
- VectorAccelerate compiles
- 5+ new tests pass
- No breaking changes to existing API

---

## Rollback Plan

If any batch introduces issues:

1. **Batch 1**: Revert VectorCore changes, other batches can proceed without `VSKError` conformance
2. **Batch 4**: Simply revert the extension, no dependencies
3. **Batch 9**: Revert VectorAccelerate changes, Batch 10 will be delayed

---

## Notes for GournalCore Team

After Week 1 batches are merged:

- `EmbeddingConfiguration` will have factory methods (Batch 4)
- VectorCore will have `VectorProducer` protocol you can prepare for (Batch 1)
- Full `EmbeddingGenerator` will be available after Week 2 (Batch 5)

Recommended preparation:
1. Plan to use configuration factories instead of manual config
2. Design your embedding consumer code to work with `VectorProducer` protocol
3. Prepare progress UI components for `OperationProgress` / `BatchProgress`
